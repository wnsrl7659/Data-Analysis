{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References:\n",
    "    www.python.org\n",
    "    www.numpy.org\n",
    "    www.matplotlib.org\n",
    "    https://pandas.pydata.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions/feedback: petert@digipen.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "* Goal\n",
    "* Examples\n",
    "* Measures and Testing\n",
    "* Error Types\n",
    "* Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing\n",
    "\n",
    "#### Goal: estimate a quantity to verify a hypothesis\n",
    "\n",
    "#### Examples:\n",
    "- decide if a coin is fair\n",
    "- 50% of children born are male\n",
    "- the average value of a die roll is 5\n",
    "- taller fathers have taller sons\n",
    "- shorter mothers have shorter daughters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measures and Testing:\n",
    "- choose a parameter (sample statistic) to use as a measure\n",
    "- sample the parameter and decide if the hypothesis is false, based on sampled data\n",
    "\n",
    "Such hypothesis is called the **Null Hypothesis**: $H_0$\n",
    "\n",
    "An alternative hypothesis is called **Alternative Hypothesis**: $H_1$ (or $H_a$)\n",
    "\n",
    "We can test/simulate against an alternative hypothesis.\n",
    "\n",
    "Aim to **calculate probabilities** which will lead us to\n",
    "- reject<br>\n",
    "    or\n",
    "- not reject\n",
    "the null hypothesis in favor of the alternative hypothesis.\n",
    "\n",
    "Possible outcomes of such **hypothesis test**:\n",
    "- reject $H_0$ in favor of $H_1$ - That is $H_0$ is concluded **not True**<br>\n",
    "    or\n",
    "- not reject $H_0$ in favor of $H_1$ - That is $H_0$ could be True but could not conclude as there still is a small probability that $H_0$ is false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example:\n",
    "You get a coin, how can you verify if it is a fair coin?\n",
    "\n",
    "- Let p = p (heads)  -  the probability of the coin landing on heads.\n",
    "- Let $H_0$ be the null hypothesis: $p = 0.5$ - that is the coin **IS** fair\n",
    "- Then $H_1$ is an alternative hypothesis: $p \\ne 0.5$ - that is the coin **IS NOT** fair<br>\n",
    "Note that there can be other alternative hypothesis:\n",
    "    - $H_1$ : $p < 0.5$\n",
    "    - $H_1$ : $p > 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be two **types of error**:\n",
    "1. **Type I** error (error at α-level)\n",
    "    - measures the probability that we reject $H_0$ null hypothesis even when it is **true**. For example, data suggests that the coin is not fair, when in fact it is.\n",
    "    - this can happen when an unlikely event occurres, for example: all 50 coin flips are landing on heads\n",
    "    - α is the maximum error of Type I that we are willing to accept in our measurement (α is arbitrary!)\n",
    "    - Type I error is called the error at α-level, or the significance level α for the test\n",
    "\n",
    "    Commonly used significance levels:\n",
    "        - α = 0.05 refers to 95% confidence to make the right decision\n",
    "        - α = 0.01 refers to 99% confidence to make the right decision\n",
    "\n",
    "\n",
    "2. **Type II** error (error at β-level)\n",
    "    - measures the probability that we do not reject $H_0$ null hypothesis when it is **false**. For example, data indicates that the coin could still be fair, when in fact it is a biased coin.\n",
    "    - The probability that a test does not cause Type II error gives the power of the test.\n",
    "\n",
    "Notes:\n",
    "- $H_0: p \\ne 0.5$ is a two-tailed test, confidence interval can be used\n",
    "- $H_0: p > 0.5$ and $H_0: p < 0.5$ are a one-sided tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "<TABLE>\n",
    "    <TR>\n",
    "        <TD></TD>\n",
    "        <TD>$H_0$ is True</TD>\n",
    "        <TD>$H_0$ is False</TD>\n",
    "    </TR>\n",
    "    <TR>\n",
    "        <TD>Reject $H_0$</TD>\n",
    "        <TD><font color='red'>Type I error</font></TD>\n",
    "        <TD><center><font color='green'>OK</font></center></TD>\n",
    "    </TR>\n",
    "    <TR>\n",
    "    <TD>Not reject $H_0$</TD>\n",
    "    <TD><center><font color='green'>OK</font></center></TD>\n",
    "    <TD><font color='red'>Type II error</font></TD>\n",
    "    </TR>\n",
    "</TABLE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the example\n",
    "#### Example:\n",
    "You get a coin, how can you verify if it is a fair coin?\n",
    "\n",
    "- Let p = p (heads)  -  the probability of the coin landing on heads.\n",
    "- Let $H_0$ be the null hypothesis: $p = 0.5$ - that is the coin is **fair**\n",
    "- Then $H_1$ is an alternative hypothesis: $p \\ne 0.5$ - that is the coin is **biased**<br>\n",
    "\n",
    "Error types:\n",
    "+ Type I error: when the estimate for the proportion of heads is not close to 50%, ==> we reject $H_0$, however the coin is fair\n",
    "+ Type II error: when the estimate for the proportion of heads is close to 50%, however the coin is biased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an experiment:\n",
    "- flip a coin 40000 times\n",
    "- $p$ is the probability of landing on heads\n",
    "- $H_0$: $p = 0.5$\n",
    "- $H_1$: $p \\ne 0.5$\n",
    "- $α = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coin flips 40000 times\n",
    "flips = np.random.choice(2, 40000)\n",
    "flips[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2499929775000001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance of flips\n",
    "flip_var = np.var(flips)\n",
    "flip_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50265"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of flips\n",
    "flip_mean = np.mean(flips)\n",
    "flip_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI lower bound: 0.495\n",
      "CI upper bound: 0.505\n",
      "0.50265 falls within the CI, therefore there is no evidence to reject the null hypothesis\n",
      "         We think the coin is Fair!\n"
     ]
    }
   ],
   "source": [
    "# calculate 95% confidence interval\n",
    "# 95% means using +/- 2 * std\n",
    "# std is sqrt of var\n",
    "# var is p(1-p) / #flips\n",
    "print('CI lower bound:', 0.5 - 2 * np.sqrt(0.5 * (1 - 0.5) / len(flips)))\n",
    "print('CI upper bound:', 0.5 + 2 * np.sqrt(0.5 * (1 - 0.5) / len(flips)))\n",
    "\n",
    "print(flip_mean, 'falls within the CI, therefore there is no evidence to reject the null hypothesis\\n         We think the coin is Fair!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run the same experiment:\n",
    "- flip a coin 40000 times\n",
    "- $p$ is the probability of landing on heads\n",
    "- $H_0$: $p = 0.5$\n",
    "- $H_1$: $p \\ne 0.5$\n",
    "- $α = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flips_b = np.random.choice(2, 40000, p=[0.51, 0.49]) # note that we made the coin biased by assigning differnt than 50% probability to them\n",
    "flips_b[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24997217437499994"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variance of flips\n",
    "np.var(flips_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.494725"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean of flips\n",
    "np.mean(flips_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI lower bound: 0.495\n",
      "CI upper bound: 0.505\n",
      "0.494725 falls outside of the CI, therefore we reject the null hypothesis\n",
      "         We think the coin is Biased!\n"
     ]
    }
   ],
   "source": [
    "#calculated 95% confidence interval\n",
    "# 95% means using +/- 2 * std\n",
    "print('CI lower bound:', 0.5 - 2 * np.sqrt(0.5 * (1 - 0.5) / len(flips_b)))\n",
    "print('CI upper bound:', 0.5 + 2 * np.sqrt(0.5 * (1 - 0.5) / len(flips_b)))\n",
    "\n",
    "print(np.mean(flips_b), 'falls outside of the CI, therefore we reject the null hypothesis\\n         We think the coin is Biased!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run this experiment many times and plot the histogram of the average outcomes of landing on heads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the fair coin\n",
    "l = []\n",
    "for i in range(1000):\n",
    "    l.append(np.mean(np.random.choice(2, 40000)))\n",
    "plt.hist(l, bins=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the biased coin\n",
    "l_b = []\n",
    "for i in range(1000):\n",
    "    l_b.append(np.mean(np.random.choice(2, 40000, p=[0.51, 0.49])))\n",
    "plt.hist(l_b, bins=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display boxbplots of the simulations including the theoretic confidence intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "plt.axhline(y = 0.5 - 2 * np.sqrt(0.5 * (1 - 0.5) / len(flips)), color='red', linestyle='dashed', label='95% CI lower bound')\n",
    "plt.axhline(y = 0.5 + 2 * np.sqrt(0.5 * (1 - 0.5) / len(flips)), color='red', linestyle='dashdot', label='95% CI upper bound')\n",
    "plt.axhline(y = 0.5 - 3 * np.sqrt(0.5 * (1 - 0.5) / len(flips)), color='blue', linestyle='dashed', label='99% CI lower bound')\n",
    "plt.axhline(y = 0.5 + 3 * np.sqrt(0.5 * (1 - 0.5) / len(flips)), color='blue', linestyle='dashdot', label='99% CI upper bound')\n",
    "#plt.boxplot(l, notch=True)\n",
    "plt.boxplot(l_b, notch=True)\n",
    "plt.title('Confidence Intervals and Coin Flip #Heads')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Another experiment using the Galton Families dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('galtonfamilies.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $H_0$: The average *father : mother* ratio is **not** the same as the average *son : daughter* ratio\n",
    "- $H_1$: The average *father : mother* ratio is the same as the average *son : daughter* ratio\n",
    "- $α = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many families are there?\n",
    "len(df['family'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use groupby to reduce the dataframe to families\n",
    "fmr = df.groupby('family').mean()['father'] / df.groupby('family').mean()['mother']\n",
    "fmr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# female average childHeight\n",
    "fac = df[df['gender'] == 'female'].groupby('family').mean()\n",
    "display(fac.head())\n",
    "fac.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male average childHeight\n",
    "mac = df[df['gender'] == 'male'].groupby('family').mean()\n",
    "display(mac.head())\n",
    "mac.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(mac, fac, on='family', how='inner', suffixes=['_male', '_female'])\n",
    "display(df_merged.head())\n",
    "df_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr = df_merged['childHeight_male'] / df_merged['childHeight_female']\n",
    "sdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=200)\n",
    "data = [fmr, sdr]\n",
    "plt.boxplot(data, notch=True)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=200)\n",
    "data = [fmr, sdr]\n",
    "plt.boxplot(data, notch=True, showfliers=False)\n",
    "plt.axhline(y=1.08515, linestyle='dashed', color='blue', linewidth=0.5)\n",
    "plt.axhline(y=1.07583, linestyle='dashed', color='blue', linewidth=0.5)\n",
    "plt.axhline(y=1.09532, linestyle='dashed', color='red', linewidth=0.5)\n",
    "plt.axhline(y=1.07879, linestyle='dashed', color='red', linewidth=0.5)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If two statistics have non-overlapping confidence intervals, they are necessarily significantly different.\n",
    "\n",
    "If two statistics have overlapping confidence intervals: it is not necessarily true that they are not significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we cannot reject that father:mother and son:daughter ratio are different. We cannot reject H0, though it may be true!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that using $\\alpha = 0.01$ the confidence intervals won't overlap. Then we can reject H0 so the ratios can be considered significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homework 22.1:\n",
    "Run two experiments\n",
    "- flip a coin 40000 times\n",
    "    - use np.random.choice(2, 40000), that is a fair coin simulation<br>\n",
    "        or\n",
    "    - use np.random.choice(2, 40000, p=[0.51, 0.49]), that is a fair coin simulation\n",
    "- use $α = 0.01$\n",
    "- $H_0$: $p = 0.5$\n",
    "- $H_1$: $p \\ne 0.5$\n",
    "\n",
    "Can you decide (in each cases) if the coin is fair or biased?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 22.1 code comes here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homework 22.2:\n",
    "Run an experiment using the galtonfamilies dataset:\n",
    "- $H_0$: The average *father : mother* ratio is **not** the same as the average *son : daughter* ratio\n",
    "- $H_1$: The average *father : mother* ratio is the same as the average *son : daughter* ratio\n",
    "- $α = 0.01$\n",
    "\n",
    "Can you reject the null hypothesis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 22.2 code comes here:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
